export const teamData = {
  vaishnavi: {
    id: 'vaishnavi',
    name: 'Vaishnavi Adhao',
    role: 'AI Solutions Architect & AI Lead',
    tagline: 'Transforming data into intelligent solutions ü§ñ',
    avatar: 'üë©‚Äçüíº',
    email: 'vaishnaviadhao33@gmail.com',
    phone: '+91 8956662057',
    location: 'Pune, Maharashtra, India',
    linkedin: 'https://www.linkedin.com/in/vaishnavi-adhao/',
    github: 'https://github.com/vaishnaviadhao',
    summary: 'I am an AI and Machine Learning expert with 2+ years of experience in analytics, AI solutions, and predictive modeling. I have a strong track record of managing AI and ML projects, optimizing data-driven KPIs, and leveraging Python, SQL, and Excel to drive efficiency. Skilled in TensorFlow, Scikit-Learn, and Hugging Face, I thrive on solving complex challenges and developing innovative AI solutions for business impact.',
    skills: {
      'Machine Learning & AI': ['TensorFlow', 'Scikit-Learn', 'Hugging Face', 'XGBoost', 'Vertex AI', 'RAG', 'LLM Models'],
      'Programming & Data': ['Python', 'Oracle SQL', 'Data Science', 'Data Manipulation', 'Statistics Analysis'],
      'Tools & Platforms': ['AWS SageMaker', 'Jupyter', 'Google Analytics', 'GitHub', 'Crawl4AI', 'Playwright'],
      'Analytics & Modeling': ['Predictive Analysis', 'Decision Trees', 'Statistical Analysis', 'Data-driven KPIs']
    },
    experience: [
      {
        company: 'ProPlus Data',
        role: 'AI Solutions Architect / AI Lead',
        duration: 'Dec 2023 - Present',
        description: 'Led AI strategy, utilizing data-driven insights and machine learning to drive successful project outcomes. Developed and implemented AI solutions, including LLM models, to automate processes and enhance efficiency. Applied skills in Python, SQL, and statistical analysis to optimize workflows, reduce manual effort, and deliver actionable insights.'
      },
      {
        company: 'Future Market Insights',
        role: 'Associate Consultant',
        duration: 'Jan 2023 - Oct 2023',
        description: 'Defined project scope, identified challenges, and designed execution flows. Managed data collection, analysis, and reporting to drive insights at this market research and consulting firm.'
      }
    ],
    education: [
      {
        degree: 'Master\'s Degree in Statistics',
        institution: 'MIT-WPU',
        duration: 'Aug 2021 - May 2023',
        grade: 'Pune, MH'
      },
      {
        degree: 'Bachelor\'s Degree in Statistics',
        institution: 'Fergusson College (Autonomous)',
        duration: 'Aug 2018 - May 2021',
        grade: 'Pune, MH'
      }
    ],
    projects: [
      {
        name: 'ML Model on AWS SageMaker',
        description: 'Built an ML model on AWS SageMaker to predict purchase behavior. Deployed using XGBoost and integrated with AWS Lambda and S3.',
        tech: ['AWS SageMaker', 'XGBoost', 'AWS Lambda', 'S3'],
        link: '#'
      },
      {
        name: 'LLM Integration with Hugging Face',
        description: 'Integrated Large Language Models (LLMs) into AI workflows for automation and efficiency. Utilized Hugging Face and Crawl4AI for AI-driven automation and text processing.',
        tech: ['Hugging Face', 'Crawl4AI', 'LLM', 'AI Automation'],
        link: '#'
      }
    ],
    certifications: [
      'Google Analytics',
      'Oracle SQL',
      'Python Programming'
    ],
    achievements: [
      'Employee of the Quarter at ProPlus Data (Q1, Q3, Q4)',
      'AI Strategy Leadership - 95% project success rate with 30% efficiency increase',
      'Employee of the Quarter at Future Market Insights'
    ]
  },

  vidhisha: {
    id: 'vidhisha',
    name: 'Vidhisha Kamble',
    role: 'Full Stack Developer & AI Engineer',
    tagline: 'Crafting intelligent solutions with code ü§ñ',
    avatar: 'üë©‚Äçüíª',
    email: 'veeekamble@gmail.com',
    phone: '+91 93254 91479',
    location: 'Hadapsar, Pune, Maharashtra',
    linkedin: 'https://www.linkedin.com/in/vidhisha-kamble-435b73213/',
    github: 'https://github.com/veeuu/',
    summary: 'Computer Science graduate from Modern College, Pune, with a strong foundation in backend development and core computing principles. Proactive, adaptable, and committed to continuous learning. Seeking a full-time role to contribute technical expertise and grow within an innovative team environment.',
    skills: {
      'Programming Languages': ['Python', 'C/C++', 'Java', 'PHP', 'HTML/CSS', 'React', 'JavaScript', 'MySQL', 'PostgreSQL'],
      'Core Skills': ['Backend Development', 'Data Structures and Algorithms (DSA)', 'Database Management (DBMS/RDBMS)'],
      'AI/ML': ['Google Gemini', 'LangChain', 'LLMs', 'RAG', 'OCR (Tesseract)', 'BeautifulSoup', 'Playwright'],
      'Soft Skills': ['Problem Solving', 'Resourcefulness', 'Responsibility and Accountability', 'Self-Motivated', 'Adaptability and Flexibility']
    },
    experience: [
      {
        company: 'ProPlus Data Prospect Intelligence',
        role: 'AI Intern',
        duration: 'Jun 2025 - Present',
        description: 'Working on advanced web scraping and data extraction projects using tools such as Google Gemini, LangChain, LLMs, RAG, OCR (Tesseract), BeautifulSoup, Playwright, and ScrapingDog. Building intelligent data pipelines leveraging GenAI to extract, analyze, and summarize information from dynamic web content for business insights.'
      },
      {
        company: 'Ernst & Young',
        role: 'GenAI Intern',
        duration: 'Jun 2024 - Jul 2024',
        description: 'Developed an eKYC system with features like image capture, OCR-based Aadhaar extraction, and fraud detection; contributed to frontend design and backend integration using Flask API. Built a dynamic form translation solution leveraging Google Translate API for real-time text and PDF translations.'
      }
    ],
    education: [
      {
        degree: 'Bachelor of Science (Computer Science)',
        institution: 'Modern College of Arts, Commerce and Science',
        duration: '2022 - 2025',
        grade: 'CGPA: 8.2'
      },
      {
        degree: 'HSC (Science)',
        institution: 'Late Bhairomal Tanwani Junior College',
        duration: '2020 - 2021',
        grade: 'Percentage: 81%'
      }
    ],
    projects: [
      {
        name: 'Pixel Art Platformer Game (Mario-style)',
        description: 'Working on a 2D pixel art game focusing on character movement, obstacle navigation, and collectible interactions. Designed game elements and animations using Piskel and UI layouts in Figma.',
        tech: ['Unity', 'GameMaker', 'Canva', 'C', 'Piskel', 'Figma'],
        link: 'https://github.com/veeuu/2D-PixelGame-MarioStyle'
      },
      {
        name: 'AI Interview Assistant',
        description: 'Built an AI-powered tool to prepare for interviews with features like a dynamic question generator, mock interview setup using TTS and STT, and feedback ratings.',
        tech: ['PHP', 'React', 'Google Gemini', 'SQL'],
        link: 'https://github.com/veeuu/AI-Interview-Assistant'
      },
      {
        name: 'AI Study Helper',
        description: 'Developed a tool to upload study documents and generate fill-in-the-blanks, true/false, short-answer, and long-answer questions with answer keys.',
        tech: ['Java', 'React', 'RAG'],
        link: 'https://github.com/veeuu/AI-Study-Helper'
      }
    ],
    certifications: [
      'The Joy of Computing using Python (NPTEL)',
      'Programming in Modern C++ (NPTEL)'
    ]
  },

  siddhi: {
    id: 'siddhi',
    name: 'Siddhi Dilip Hadap',
    role: 'AI Specialist & Data Scientist',
    tagline: 'Turning data into insights, chaos into clarity üìä',
    avatar: 'üë©‚Äçüî¨',
    email: 'siddhihadap7@gmail.com',
    phone: '+91 9022926232',
    location: 'Pune, Maharashtra, India',
    linkedin: 'www.linkedin.com/in/siddhi-hadap-01314a1a4/',
    github: 'github.com/siddhi-hadap',
    summary: 'Results-driven Data Science and Data Analyst with more than 2 years of experience in data management and analytics across IT and manufacturing. Skilled in data preprocessing, MongoDB-based unstructured data storage, quarterly database maintenance, and building ML solutions. Currently leading web-scraping automation using Gemini models, semantic search, vector DBs, and Jina.ai to improve accuracy and speed. Proficient in Power BI and Tableau for actionable dashboards and experienced in anomaly detection and predictive modeling using Python.',
    skills: {
      'Programming & Data Science': ['Python (Pandas, NumPy, Scikit-learn, Regex)', 'Machine Learning', 'Anomaly Detection', 'Data Preprocessing'],
      'Web Scraping & Search': ['Web Scraping (BeautifulSoup, Selenium, APIs)', 'Gemini API (Google)', 'Jina.ai', 'Semantic Search', 'Vector Databases'],
      'Databases': ['MongoDB (Unstructured Data Storage & Management)', 'SQL (Querying, Joins, Filtering)'],
      'Data Visualization & Reporting': ['Power BI (Dashboards, Power Query)', 'Tableau (Visual Analytics)', 'Excel (Pivot Tables, VLOOKUP)'],
      'Tools & Platforms': ['LLaMA Models', 'Instant Data Scraper', 'Scrap Similar', 'Git']
    },
    experience: [
      {
        company: 'Pro Plus Data Pvt Ltd',
        role: 'AI Specialist',
        duration: 'Jul 2025 - Present',
        description: 'Designed and deployed AI-driven automation pipelines integrating LLaMA and Gemini models to optimize data processing and quality assurance. Led centralized MongoDB-based AI data systems for scalable unstructured data storage. Implemented intelligent data validation using semantic search and embeddings, improving web-scraped and structured data accuracy by over 90%. Collaborated cross-functionally to integrate AI modules with analytics and visualization systems.'
      },
      {
        company: 'Pro Plus Data Pvt Ltd',
        role: 'Data Science Intern',
        duration: 'Jan 2025 - Jul 2025',
        description: 'Preprocessed and structured unorganized data for storage and analysis in MongoDB, maintained quarterly database upkeep, and automated web scraping pipelines initially using LLaMA models and later integrated Gemini via API. Implemented semantic search with vector DBs and used Jina.ai to enhance scraping accuracy and response time.'
      },
      {
        company: 'Pro Plus Data Pvt Ltd',
        role: 'Data Analyst',
        duration: 'Aug 2022 - Aug 2023',
        description: 'Analyzed technology-driven datasets to uncover trends and created interactive dashboards in Tableau. Maintained internal data systems using Excel and SQL to ensure data integrity and usability for stakeholders.'
      },
      {
        company: 'Sandvik Coromant Asia Pvt. Ltd.',
        role: 'Data Science Intern',
        duration: 'Mar 2022 - Jul 2022',
        description: 'Worked with Maintenance to monitor machine operation data for predictive maintenance. Developed Power BI dashboards and built an anomaly detection model in Python to identify abnormal machine behavior.'
      },
      {
        company: 'Skills-Enrich',
        role: 'Data Scientist Intern',
        duration: 'Aug 2021 - Sep 2021',
        description: 'Conducted data-driven research and applied core data science techniques to extract insights from diverse datasets supporting business decisions.'
      }
    ],
    education: [
      {
        degree: 'Master of Data Science',
        institution: "Dr. D.Y. Patil ACS College",
        duration: '2025',
        grade: 'CGPA: 9.64/10'
      },
      {
        degree: 'Bachelor of Data Science',
        institution: 'Symbiosis Skills and Professional University',
        duration: '2022',
        grade: 'CGPA: 8.84/10'
      }
    ],
    projects: [
      {
        name: 'Web Scraping Automation & Validation',
        description: 'Built automated web-scraping pipelines using LLaMA and Gemini models, integrated semantic search and vector DBs for validation, and used Jina.ai to improve retrieval accuracy and speed.',
        tech: ['Python', 'Gemini API', 'Jina.ai', 'Vector DBs'],
        link: '#'
      },
      {
        name: 'MongoDB Data Pipeline',
        description: 'Designed scalable data processing pipelines for unstructured data storage and quarterly maintenance workflows.',
        tech: ['MongoDB', 'Python'],
        link: '#'
      },
      {
        name: 'Predictive Maintenance Dashboard',
        description: 'Developed Power BI dashboards and an anomaly detection model to monitor machine health and reduce downtime.',
        tech: ['Power BI', 'Python', 'Machine Learning'],
        link: '#'
      }
    ],
    certifications: [
      'MongoDB Certified Developer',
      'Tableau Desktop Specialist',
      'Google Data Analytics Certificate'
    ]
  },

  swapnil: {
    id: 'swapnil',
    name: 'Swapnil Laxman Jadhav',
    role: 'Backend Developer (Node.js)',
    tagline: 'Building robust backends that scale üöÄ',
    avatar: 'üë®‚Äçüíª',
    email: 'swapniljadhav9137@gmail.com',
    phone: '+91 8329326868',
    location: 'Pune, India',
    linkedin: 'https://www.linkedin.com/in/s-jadhav/',
    github: 'https://github.com/swapnil-jadhav-2608',
    summary: 'Node.js Backend Developer with 2+ years of experience in backend systems, web scraping, and API integrations. Skilled in building scalable data processing platforms using Node.js, Express.js, MongoDB, MySQL, and AWS. Strong focus on scalability, performance optimization, and real-time data handling.',
    skills: {
      'Backend': ['Node.js', 'Express.js', 'REST APIs', 'JWT', 'OAuth'],
      'Database': ['MongoDB', 'MySQL'],
      'Frontend': ['HTML', 'CSS', 'JavaScript'],
      'Cloud & DevOps': ['AWS EC2', 'Nginx', 'Git', 'GitHub', 'CI/CD'],
      'Other': ['Web Scraping', 'API Development', 'Performance Optimization']
    },
    experience: [
      {
        company: 'ProPlus Data Pvt Ltd',
        role: 'Web Tech Researcher',
        duration: 'May 2025 - Present',
        description: 'Designed and implemented advanced web scraping scripts for large-scale data collection using Node.js, TypeScript, React, and MongoDB. Applied AI models (LLaMA, Gemini, ChatGPT) for fine-tuning, training, and quality checks of extracted datasets.'
      },
      {
        company: 'AchetyaB2B Solutions LLP',
        role: 'Backend Developer',
        duration: 'Jul 2023 - Apr 2025',
        description: 'Developed and optimized scalable backend services and RESTful APIs using Node.js, Express.js, and MongoDB for a real-time business intelligence platform. Engineered the Data Finder & Lead Generator tool using Puppeteer for high-speed web scraping.'
      }
    ],
    education: [
      {
        degree: 'B.Tech in Computer Science & Engineering',
        institution: 'DBATU University, Lonere (Bhagwant Institute of Technology, Barshi)',
        duration: '2016 - 2020',
        grade: 'CGPA: 8.1/10'
      }
    ],
    projects: [
      {
        name: 'CAD Block Viewer',
        description: 'Built a lightweight web app to preview and interact with CAD blocks directly in the browser. Implemented file upload and responsive UI for architects and engineers.',
        tech: ['Node.js', 'Express.js', 'JavaScript'],
        link: 'https://github.com/swapnil-jadhav-2608/CAD-Block-Viewer'
      },
      {
        name: 'Data Processing Platform',
        description: 'Architected centralized dashboard platform providing single interface for multiple automation tools',
        tech: ['Node.js', 'MongoDB', 'WebSockets', 'AWS'],
        link: 'https://github.com/swapnil-jadhav-2608/user-feedback-system'
      }
    ],
    certifications: [
      'NASSCOM: Cloud Application Developer',
      'AWS Fundamentals'
    ]
  },

  krishna: {
    id: 'krishna',
    name: 'Krishna Birla',
    role: 'Backend Developer (Python) & ML Engineer',
    tagline: 'Python-powered solutions for tomorrow üêç',
    avatar: 'üë®‚Äçüî¨',
    email: 'krishnabirla336@gmail.com',
    phone: '+91 9588620228',
    location: 'Pashan, Pune, Maharashtra',
    linkedin: 'https://www.linkedin.com/in/krishnabirla/',
    github: 'https://github.com/Krishna9588',
    summary: 'I am passionate about artificial intelligence, machine learning, and backend development. I enjoy working on impactful projects that help me grow and contribute meaningfully. I adapt quickly, collaborate effectively in teams, and communicate confidently.',
    skills: {
      'Languages': ['Python', 'MySQL', 'JavaScript'],
      'Frontend': ['HTML', 'CSS'],
      'Technologies': ['Git', 'GitHub', 'Google Collab', 'Huggingface', 'AWS'],
      'Concepts': ['Object-Oriented Programming', 'Machine Learning', 'RAG'],
      'Python Libraries': ['Playwright', 'Selenium', 'scikit-learn'],
      'Soft Skills': ['Communication', 'Problem Solving', 'Team Work']
    },
    experience: [
      {
        company: 'ProPlus Data',
        role: 'AI Intern',
        duration: 'June 2025 - Present',
        description: 'Working on AI-powered data processing and machine learning projects'
      },
      {
        company: 'Datakind Financial Inclusion DataKit',
        role: 'Open Source Contributor',
        duration: 'Mar 2025 - Apr 2025',
        description: 'Contributed to open source financial inclusion projects'
      },
      {
        company: 'Aroma Brand Solution',
        role: 'Backend Developer Intern',
        duration: 'Jan 2025 - Mar 2025',
        description: 'Developed backend solutions using Python and related technologies'
      }
    ],
    education: [
      {
        degree: 'B.E. in Artificial Intelligence and Machine Learning',
        institution: 'ISBM College of Engineering, Pune',
        duration: 'Final Year',
        grade: 'CGPA: 8.31/10'
      }
    ],
    projects: [
      {
        name: 'Verification Engine',
        description: 'Created an automated engine to verify technology stacks by analyzing web pages and PDF documents, cutting manual effort by 80%. Used Python for web scraping and LLM APIs for contextual analysis.',
        tech: ['Python', 'LLM', 'Selenium', 'Playwright', 'Pandas'],
        link: 'https://github.com/Krishna9588/Verification_Engine'
      },
      {
        name: 'Botnet Detection using ML',
        description: 'Built a machine learning based botnet detection system using Python, Scikit-learn, Random Forest, and network traffic analysis on the CTU-13 dataset.',
        tech: ['Python', 'Pandas', 'Scikit-learn', 'CTU-13 Dataset'],
        link: 'https://github.com/Krishna9588/Botnet-Detection-using-ML'
      },
      {
        name: 'Marketing Analysis - Case Study',
        description: 'Analyzed two sets of structured sales data to identify the top 3 best-selling products and 10% loyal customers, supporting inventory optimization and customer retention.',
        tech: ['Python', 'Pandas', 'NumPy'],
        link: 'https://github.com/Krishna9588/Marketing-Analysis---Case-Study'
      },
      {
        name: 'Intelligent Video-Based Q & A',
        description: 'Built an AI-powered Q&A system using the YouTube API to extract subtitles and store them in a database. Applied NLP to generate 10 key questions and used Llama 3 for accurate answers.',
        tech: ['Python', 'Llama 3', 'Hugging Face', 'SQL'],
        link: 'https://github.com/Krishna9588/AI-Tutor'
      }
    ],
    certifications: [
      'Python for Data Science (Coursera)',
      'Machine Learning Fundamentals',
      'AWS Cloud Practitioner (In Progress)'
    ]
  }
};

export const teamStats = {
  totalProjects: 20,
  yearsExperience: 8,
  clientsSatisfied: 12,
  technologiesMastered: 25
};
